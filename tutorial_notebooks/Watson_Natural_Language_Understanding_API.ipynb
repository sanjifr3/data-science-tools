{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MIE1624H - Watson Analytics - Natural Language Understanding API Tutorial\n",
    "\n",
    "The Watson Analytics Natural Language Understanding service analyzes provided text (in text,url, or html format) for the specified semantic features.\n",
    "\n",
    "It can extract entities, concepts, keywords, categories, relations, sentiment, and emotions from provided text.\n",
    "\n",
    "Custom models can also be created with the Watson Knowledge Studio to detect custom entities and relations.\n",
    "\n",
    "More information regarding this service can be found in the IBM Watson Documentation: \n",
    "https://www.ibm.com/watson/developercloud/natural-language-understanding/api/v1/?python#introduction\n",
    "\n",
    "The Watson Language Classifier service also lets you build custom classifiers to classify texts provided that you have training data.\n",
    "\n",
    "You can pass this a question, and it will return a key with the best matching answer based on the classes it was trained on. \n",
    "\n",
    "More information about the classifier service can also be found in the IBM Watson Documention:\n",
    "https://www.ibm.com/watson/developercloud/natural-language-classifier/api/v1/#introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The possible features that can be extracted are as follows:\n",
    "\n",
    "- **Concepts**: \n",
    "    - Returns the concept name, relevance source, and link to the concept's DBpedia page\n",
    "    - e.g. given ibm.com, returns Social network service, Thomas J. Watson, and Lotus Software\n",
    "- **Categories**:\n",
    "    - Categorize your content into a 5-level taxonomy and returns the top 3 categories\n",
    "- **Emotion**:\n",
    "    - Detects emotions conveyed by the entire body of text\n",
    "- **Entities**:\n",
    "    - Identify people, cities, organizations, and other types of entities present in the provided text\n",
    "    - Can also specify identify emotions, and sentiments related to entities found\n",
    "- **Keywords**:\n",
    "    - Identify important keywords in the text\n",
    "    - Can also specify identify emotions, and sentiments related to keywords found\n",
    "- **MetaData**:\n",
    "    - Get document metadata for html/url inputs such as author name, title, RSS/ATOM feeds, prominent page image, and publication date\n",
    "- **Relations**:\n",
    "    - Recognize when two entities are related, and identify the type of relation\n",
    "    - E.g. \"awardedTo\" relation might connect the entities \"Nobel Prize\" and \"Albert Einstein\"\n",
    "- **SemanticRoles**:\n",
    "    - Parse sentence in subject, action, and object form\n",
    "- **Sentiment**:\n",
    "    - Analyze the general statement of your content or analyze the sentiment toward specific phrases found in the text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: watson-developer-cloud in /resources/common/.virtualenv/python3/lib/python3.5/site-packages\n",
      "Requirement already satisfied: pysolr<4.0,>=3.3 in /resources/common/.virtualenv/python3/lib/python3.5/site-packages (from watson-developer-cloud)\n",
      "Requirement already satisfied: requests<3.0,>=2.0 in /usr/local/lib/python3.5/dist-packages (from watson-developer-cloud)\n",
      "Requirement already satisfied: pyOpenSSL>=16.2.0 in /resources/common/.virtualenv/python3/lib/python3.5/site-packages (from watson-developer-cloud)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.5/dist-packages (from watson-developer-cloud)\n",
      "Requirement already satisfied: cryptography>=2.1.4 in /resources/common/.virtualenv/python3/lib/python3.5/site-packages (from pyOpenSSL>=16.2.0->watson-developer-cloud)\n",
      "Requirement already satisfied: six>=1.5.2 in /usr/lib/python3/dist-packages (from pyOpenSSL>=16.2.0->watson-developer-cloud)\n",
      "Requirement already satisfied: asn1crypto>=0.21.0 in /resources/common/.virtualenv/python3/lib/python3.5/site-packages (from cryptography>=2.1.4->pyOpenSSL>=16.2.0->watson-developer-cloud)\n",
      "Requirement already satisfied: idna>=2.1 in /usr/local/lib/python3.5/dist-packages (from cryptography>=2.1.4->pyOpenSSL>=16.2.0->watson-developer-cloud)\n",
      "Requirement already satisfied: cffi>=1.7; platform_python_implementation != \"PyPy\" in /usr/local/lib/python3.5/dist-packages (from cryptography>=2.1.4->pyOpenSSL>=16.2.0->watson-developer-cloud)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.5/dist-packages (from cffi>=1.7; platform_python_implementation != \"PyPy\"->cryptography>=2.1.4->pyOpenSSL>=16.2.0->watson-developer-cloud)\n"
     ]
    }
   ],
   "source": [
    "!pip install watson-developer-cloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from watson_developer_cloud import NaturalLanguageUnderstandingV1 as NLU\n",
    "from watson_developer_cloud.natural_language_understanding_v1 \\\n",
    "    import Features, EntitiesOptions, KeywordsOptions, ConceptsOptions,\\\n",
    "        CategoriesOptions, EmotionOptions, SemanticRolesOptions, \\\n",
    "        MetadataOptions, SentimentOptions, RelationsOptions\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insert API credentials from Bluemix\n",
    "This is found by going the API's page and looking under 'Service Credentials'. The username and password can be viewed by clicking 'View Credentials' next to your Key Name.\n",
    "\n",
    "**Copy the credentials and replace the contents of *watson_credentials.json*. Alternatively, you can just copy and paste the keys in the variables for username and password.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parse watson_credentials.json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "credentials = {}\n",
    "\n",
    "with open('watson_credentials.json') as f:\n",
    "    data = json.load(f)\n",
    "    for k in data.keys():\n",
    "        try:\n",
    "            credentials[k] = {\n",
    "                'username': data[k][0]['credentials']['username'],\n",
    "                'password': data[k][0]['credentials']['password']\n",
    "            }\n",
    "        except KeyError:\n",
    "            credentials[k] = {\n",
    "                'api_key': data[k][0]['credentials']['api_key']\n",
    "            }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get username and password for NLU\n",
    "Enter API username and password manually or add to watson credentials file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "username = ''\n",
    "password = ''\n",
    "\n",
    "if username == '' and password == '':\n",
    "    username = credentials['natural-language-understanding']['username']\n",
    "    password = credentials['natural-language-understanding']['password']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Natural Language Classifier Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nlu = NLU(\n",
    "    username=username,\n",
    "    password=password,\n",
    "    version='2017-02-27'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create some sample texts to analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample1 = \"can't decide if i should even watch the #democraticdebate or is it not worth the migraine!? #conservative #republican2016 #tcot #ycot\"\n",
    "sample2 = \"i would be afraid of taking questions too, if i were up to the crap harper's been up to. #cdnpoli\"\n",
    "sample3 = \"IBM is an American multinational technology company headquartered in Armok, New York, United States, with operations in over 170 countries.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concepts Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here we are going to analyze the following string for relevant concepts: \n",
      "IBM is an American multinational technology company headquartered in Armok, New York, United States, with operations in over 170 countries.\n"
     ]
    }
   ],
   "source": [
    "print (\"Here we are going to analyze the following string for relevant concepts: \\n{}\".format(sample3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function uses the natural language understanding object to analyze the provided text for the top 3 concepts in it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getConcepts(text):\n",
    "    response=nlu.analyze(\n",
    "        text=text,\n",
    "        features=Features(\n",
    "            concepts=ConceptsOptions(\n",
    "                # Concept Options\n",
    "                limit=3\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    print ('Raw Results: ')\n",
    "    print(json.dumps(response, indent=2))\n",
    "    \n",
    "    concepts = {}\n",
    "    for i in range(len(response['concepts'])):\n",
    "       concepts[response['concepts'][i]['text']] = response['concepts'][i]['relevance']\n",
    "                \n",
    "    return concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are the raw results and the results in a dictionary format. This text returns the top 3 relevant concepts as United States, U.S. State, and New York City with a lowest relevance score of 83.5%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Results: \n",
      "{\n",
      "  \"concepts\": [\n",
      "    {\n",
      "      \"relevance\": 0.939855,\n",
      "      \"dbpedia_resource\": \"http://dbpedia.org/resource/United_States\",\n",
      "      \"text\": \"United States\"\n",
      "    },\n",
      "    {\n",
      "      \"relevance\": 0.880671,\n",
      "      \"dbpedia_resource\": \"http://dbpedia.org/resource/New_York_City\",\n",
      "      \"text\": \"New York City\"\n",
      "    },\n",
      "    {\n",
      "      \"relevance\": 0.835175,\n",
      "      \"dbpedia_resource\": \"http://dbpedia.org/resource/U.S._state\",\n",
      "      \"text\": \"U.S. state\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"text_characters\": 139,\n",
      "    \"features\": 1,\n",
      "    \"text_units\": 1\n",
      "  },\n",
      "  \"language\": \"en\"\n",
      "}\n",
      "\n",
      "Dictionary Format:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'New York City': 0.880671, 'U.S. state': 0.835175, 'United States': 0.939855}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concepts = getConcepts(sample3)\n",
    "print ('\\nDictionary Format:')\n",
    "concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categories Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here we are going to analyze the following string for relevant categories: \n",
      "IBM is an American multinational technology company headquartered in Armok, New York, United States, with operations in over 170 countries.\n"
     ]
    }
   ],
   "source": [
    "print (\"Here we are going to analyze the following string for relevant categories: \\n{}\".format(sample3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function uses the natural language understanding object to analyze the provided text for the categories that it fits into."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getCategories(text):\n",
    "    response=nlu.analyze(\n",
    "        text=text,\n",
    "        features=Features(\n",
    "            categories=CategoriesOptions(\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    print ('Raw Results: ')\n",
    "    print(json.dumps(response, indent=2))\n",
    "    \n",
    "    categories = {}\n",
    "    for i in range(len(response['categories'])):\n",
    "       categories[response['categories'][i]['label']] = response['categories'][i]['score']\n",
    "\n",
    "    return categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are the raw results and the results in a dictionary format. This text returns 3 categories: Technology and Computing, Business Operations, and Airlines, all with relatively low scores (max 22.5%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Results: \n",
      "{\n",
      "  \"usage\": {\n",
      "    \"text_characters\": 139,\n",
      "    \"features\": 1,\n",
      "    \"text_units\": 1\n",
      "  },\n",
      "  \"categories\": [\n",
      "    {\n",
      "      \"score\": 0.224545,\n",
      "      \"label\": \"/technology and computing\"\n",
      "    },\n",
      "    {\n",
      "      \"score\": 0.196078,\n",
      "      \"label\": \"/business and industrial/business operations\"\n",
      "    },\n",
      "    {\n",
      "      \"score\": 0.147978,\n",
      "      \"label\": \"/travel/transports/air travel/airlines\"\n",
      "    }\n",
      "  ],\n",
      "  \"language\": \"en\"\n",
      "}\n",
      "\n",
      "Dictionary Format:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'/business and industrial/business operations': 0.196078,\n",
       " '/technology and computing': 0.224545,\n",
       " '/travel/transports/air travel/airlines': 0.147978}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories = getCategories(sample3)\n",
    "print ('\\nDictionary Format:')\n",
    "categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Emotion Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here we are going to analyze the following string for relevant emotions: \n",
      "can't decide if i should even watch the #democraticdebate or is it not worth the migraine!? #conservative #republican2016 #tcot #ycot\n"
     ]
    }
   ],
   "source": [
    "print (\"Here we are going to analyze the following string for relevant emotions: \\n{}\".format(sample1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function uses the natural language understanding object to analyze the provided text to find the emotion that it is conveying."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getEmotions(text):\n",
    "    response=nlu.analyze(\n",
    "        text=text,\n",
    "        features=Features(\n",
    "            emotion=EmotionOptions(\n",
    "                # Emotion options\n",
    "                #targets=['politic']\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    print ('Raw Results: ')\n",
    "    print(json.dumps(response, indent=2))\n",
    "    \n",
    "    emotions = {}\n",
    "    \n",
    "    for k,v in response['emotion']['document']['emotion'].items():\n",
    "        emotions[k] = v\n",
    "    \n",
    "    return emotions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are the raw results and the results in a dictionary format. The results features 5 types of emotions and their associated scores. In this case, the strongest emotion was disgust."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Results: \n",
      "{\n",
      "  \"emotion\": {\n",
      "    \"document\": {\n",
      "      \"emotion\": {\n",
      "        \"anger\": 0.225086,\n",
      "        \"fear\": 0.107364,\n",
      "        \"disgust\": 0.629703,\n",
      "        \"joy\": 0.01363,\n",
      "        \"sadness\": 0.366987\n",
      "      }\n",
      "    }\n",
      "  },\n",
      "  \"usage\": {\n",
      "    \"text_characters\": 133,\n",
      "    \"features\": 1,\n",
      "    \"text_units\": 1\n",
      "  },\n",
      "  \"language\": \"en\"\n",
      "}\n",
      "\n",
      "Dictionary Format:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'anger': 0.225086,\n",
       " 'disgust': 0.629703,\n",
       " 'fear': 0.107364,\n",
       " 'joy': 0.01363,\n",
       " 'sadness': 0.366987}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotions = getEmotions(sample1)\n",
    "print ('\\nDictionary Format:')\n",
    "emotions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entities Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here we are going to analyze the following string for relevant entities: \n",
      "IBM is an American multinational technology company headquartered in Armok, New York, United States, with operations in over 170 countries.\n"
     ]
    }
   ],
   "source": [
    "print (\"Here we are going to analyze the following string for relevant entities: \\n{}\".format(sample3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function uses the natural language understanding object to analyze the provided text to find relevant entities in the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getEntities(text):\n",
    "    response=nlu.analyze(\n",
    "        text=text,\n",
    "        features=Features(\n",
    "            entities=EntitiesOptions(\n",
    "                # Entities Options\n",
    "                #targets=['politic']\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    print ('Raw Results: ')\n",
    "    print(json.dumps(response, indent=2))\n",
    "    \n",
    "    entities = {}\n",
    "    \n",
    "    for i in range(len(response['entities'])):\n",
    "       entities[response['entities'][i]['text']] = response['entities'][i]['relevance']\n",
    "    \n",
    "    return entities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are the raw results and the results in a dictionary format. This text returns 4 entities that it detected in the text including: IBM, Armok, New York, and United States with relevance scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Results: \n",
      "{\n",
      "  \"usage\": {\n",
      "    \"text_characters\": 139,\n",
      "    \"features\": 1,\n",
      "    \"text_units\": 1\n",
      "  },\n",
      "  \"entities\": [\n",
      "    {\n",
      "      \"relevance\": 0.33,\n",
      "      \"count\": 1,\n",
      "      \"disambiguation\": {\n",
      "        \"name\": \"IBM\",\n",
      "        \"dbpedia_resource\": \"http://dbpedia.org/resource/IBM\",\n",
      "        \"subtype\": [\n",
      "          \"SoftwareLicense\",\n",
      "          \"OperatingSystemDeveloper\",\n",
      "          \"ProcessorManufacturer\",\n",
      "          \"SoftwareDeveloper\",\n",
      "          \"CompanyFounder\",\n",
      "          \"ProgrammingLanguageDesigner\",\n",
      "          \"ProgrammingLanguageDeveloper\"\n",
      "        ]\n",
      "      },\n",
      "      \"text\": \"IBM\",\n",
      "      \"type\": \"Company\"\n",
      "    },\n",
      "    {\n",
      "      \"relevance\": 0.33,\n",
      "      \"count\": 1,\n",
      "      \"disambiguation\": {\n",
      "        \"subtype\": [\n",
      "          \"City\"\n",
      "        ]\n",
      "      },\n",
      "      \"text\": \"Armok\",\n",
      "      \"type\": \"Location\"\n",
      "    },\n",
      "    {\n",
      "      \"relevance\": 0.33,\n",
      "      \"count\": 1,\n",
      "      \"disambiguation\": {\n",
      "        \"name\": \"New York City\",\n",
      "        \"dbpedia_resource\": \"http://dbpedia.org/resource/New_York_City\",\n",
      "        \"subtype\": [\n",
      "          \"PoliticalDistrict\",\n",
      "          \"GovernmentalJurisdiction\",\n",
      "          \"PlaceWithNeighborhoods\",\n",
      "          \"WineRegion\",\n",
      "          \"FilmScreeningVenue\",\n",
      "          \"City\"\n",
      "        ]\n",
      "      },\n",
      "      \"text\": \"New York\",\n",
      "      \"type\": \"Location\"\n",
      "    },\n",
      "    {\n",
      "      \"relevance\": 0.33,\n",
      "      \"count\": 1,\n",
      "      \"disambiguation\": {\n",
      "        \"name\": \"United States\",\n",
      "        \"dbpedia_resource\": \"http://dbpedia.org/resource/United_States\",\n",
      "        \"subtype\": [\n",
      "          \"Region\",\n",
      "          \"AdministrativeDivision\",\n",
      "          \"GovernmentalJurisdiction\",\n",
      "          \"FilmEditor\",\n",
      "          \"Country\"\n",
      "        ]\n",
      "      },\n",
      "      \"text\": \"United States\",\n",
      "      \"type\": \"Location\"\n",
      "    }\n",
      "  ],\n",
      "  \"language\": \"en\"\n",
      "}\n",
      "\n",
      "Dictionary Format:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Armok': 0.33, 'IBM': 0.33, 'New York': 0.33, 'United States': 0.33}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entities = getEntities(sample3)\n",
    "print ('\\nDictionary Format:')\n",
    "entities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keywords Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here we are going to analyze the following string for relevant keywords: \n",
      "i would be afraid of taking questions too, if i were up to the crap harper's been up to. #cdnpoli\n"
     ]
    }
   ],
   "source": [
    "print (\"Here we are going to analyze the following string for relevant keywords: \\n{}\".format(sample2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function uses the natural language understanding object to analyze the provided text to find relevant keywords with its related emotions and sentiments in the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getKeywords(text):\n",
    "    response=nlu.analyze(\n",
    "        text=text,\n",
    "        features=Features(\n",
    "            keywords = KeywordsOptions(\n",
    "              # Keywords Option\n",
    "              emotion=True,\n",
    "              sentiment=True,\n",
    "              limit=3\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    print ('Raw Results: ')\n",
    "    print(json.dumps(response, indent=2))\n",
    "    \n",
    "    keywords = {}\n",
    "    for keyword in response['keywords']:\n",
    "        emotions = {}\n",
    "        if 'emotion' in keyword:\n",
    "            for k,v in keyword['emotion'].items():\n",
    "                emotions[k] = v\n",
    "        sentiment = {}\n",
    "        if 'sentiment' in keyword:\n",
    "            if 'label' in keyword['sentiment']:\n",
    "                sentiment[keyword['sentiment']['label']] = keyword['sentiment']['score']\n",
    "            else:\n",
    "                sentiment = keyword['sentiment']['score']\n",
    "                      \n",
    "        keywords[keyword['text']] = {}\n",
    "        keywords[keyword['text']]['relevance'] = keyword['relevance']\n",
    "        keywords[keyword['text']]['emotions'] = emotions\n",
    "        keywords[keyword['text']]['sentiment'] = sentiment\n",
    "        \n",
    "    return keywords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are the raw results and the results in a dictionary format. This text returns two relevant keywords: crap harper, and questions. Crap hraper is highly relevant with a highly negative sentiment score. Questions is less relevant but has a high score for fear, and highly negative sentiment value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Results: \n",
      "{\n",
      "  \"usage\": {\n",
      "    \"text_characters\": 97,\n",
      "    \"features\": 1,\n",
      "    \"text_units\": 1\n",
      "  },\n",
      "  \"keywords\": [\n",
      "    {\n",
      "      \"relevance\": 0.993118,\n",
      "      \"text\": \"crap harper\",\n",
      "      \"sentiment\": {\n",
      "        \"score\": -0.832073,\n",
      "        \"label\": \"negative\"\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"relevance\": 0.483106,\n",
      "      \"emotion\": {\n",
      "        \"anger\": 0.018854,\n",
      "        \"fear\": 0.719337,\n",
      "        \"disgust\": 0.028256,\n",
      "        \"joy\": 0.010041,\n",
      "        \"sadness\": 0.049893\n",
      "      },\n",
      "      \"text\": \"questions\",\n",
      "      \"sentiment\": {\n",
      "        \"score\": -0.850843,\n",
      "        \"label\": \"negative\"\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"language\": \"en\"\n",
      "}\n",
      "\n",
      "Dictionary Format:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'crap harper': {'emotions': {},\n",
       "  'relevance': 0.993118,\n",
       "  'sentiment': {'negative': -0.832073}},\n",
       " 'questions': {'emotions': {'anger': 0.018854,\n",
       "   'disgust': 0.028256,\n",
       "   'fear': 0.719337,\n",
       "   'joy': 0.010041,\n",
       "   'sadness': 0.049893},\n",
       "  'relevance': 0.483106,\n",
       "  'sentiment': {'negative': -0.850843}}}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keywords = getKeywords(sample2)\n",
    "print ('\\nDictionary Format:')\n",
    "keywords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relations Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here we are going to analyze the following string for relevant relations: \n",
      "IBM is an American multinational technology company headquartered in Armok, New York, United States, with operations in over 170 countries.\n"
     ]
    }
   ],
   "source": [
    "print (\"Here we are going to analyze the following string for relevant relations: \\n{}\".format(sample3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function uses the natural language understanding object to analyze the provided text to find relevant entities in the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getRelations(text):\n",
    "    response=nlu.analyze(\n",
    "        text=text,\n",
    "        features=Features(\n",
    "            relations=RelationsOptions(\n",
    "                # Relations Options\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    print ('Raw Results: ')\n",
    "    print(json.dumps(response, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are the raw results. The input text returns relations in the text such as \"multinational technology company\" is \"basedIn\" \"American\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Results: \n",
      "{\n",
      "  \"relations\": [\n",
      "    {\n",
      "      \"score\": 0.385011,\n",
      "      \"arguments\": [\n",
      "        {\n",
      "          \"entities\": [\n",
      "            {\n",
      "              \"text\": \"multinational technology company\",\n",
      "              \"type\": \"Organization\"\n",
      "            }\n",
      "          ],\n",
      "          \"text\": \"multinational technology company\",\n",
      "          \"location\": [\n",
      "            19,\n",
      "            51\n",
      "          ]\n",
      "        },\n",
      "        {\n",
      "          \"entities\": [\n",
      "            {\n",
      "              \"disambiguation\": {\n",
      "                \"subtype\": [\n",
      "                  \"Country\"\n",
      "                ]\n",
      "              },\n",
      "              \"text\": \"American\",\n",
      "              \"type\": \"GeopoliticalEntity\"\n",
      "            }\n",
      "          ],\n",
      "          \"text\": \"American\",\n",
      "          \"location\": [\n",
      "            10,\n",
      "            18\n",
      "          ]\n",
      "        }\n",
      "      ],\n",
      "      \"sentence\": \"IBM is an American multinational technology company headquartered in Armok, New York, United States, with operations in over 170 countries.\",\n",
      "      \"type\": \"basedIn\"\n",
      "    },\n",
      "    {\n",
      "      \"score\": 0.507149,\n",
      "      \"arguments\": [\n",
      "        {\n",
      "          \"entities\": [\n",
      "            {\n",
      "              \"text\": \"multinational technology company\",\n",
      "              \"type\": \"Organization\"\n",
      "            }\n",
      "          ],\n",
      "          \"text\": \"multinational technology company\",\n",
      "          \"location\": [\n",
      "            19,\n",
      "            51\n",
      "          ]\n",
      "        },\n",
      "        {\n",
      "          \"entities\": [\n",
      "            {\n",
      "              \"text\": \"Armok\",\n",
      "              \"type\": \"GeopoliticalEntity\"\n",
      "            }\n",
      "          ],\n",
      "          \"text\": \"Armok\",\n",
      "          \"location\": [\n",
      "            69,\n",
      "            74\n",
      "          ]\n",
      "        }\n",
      "      ],\n",
      "      \"sentence\": \"IBM is an American multinational technology company headquartered in Armok, New York, United States, with operations in over 170 countries.\",\n",
      "      \"type\": \"basedIn\"\n",
      "    },\n",
      "    {\n",
      "      \"score\": 0.547435,\n",
      "      \"arguments\": [\n",
      "        {\n",
      "          \"entities\": [\n",
      "            {\n",
      "              \"text\": \"Armok\",\n",
      "              \"type\": \"GeopoliticalEntity\"\n",
      "            }\n",
      "          ],\n",
      "          \"text\": \"Armok\",\n",
      "          \"location\": [\n",
      "            69,\n",
      "            74\n",
      "          ]\n",
      "        },\n",
      "        {\n",
      "          \"entities\": [\n",
      "            {\n",
      "              \"text\": \"New York\",\n",
      "              \"type\": \"GeopoliticalEntity\"\n",
      "            }\n",
      "          ],\n",
      "          \"text\": \"New York\",\n",
      "          \"location\": [\n",
      "            76,\n",
      "            84\n",
      "          ]\n",
      "        }\n",
      "      ],\n",
      "      \"sentence\": \"IBM is an American multinational technology company headquartered in Armok, New York, United States, with operations in over 170 countries.\",\n",
      "      \"type\": \"locatedAt\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"text_characters\": 139,\n",
      "    \"features\": 1,\n",
      "    \"text_units\": 1\n",
      "  },\n",
      "  \"language\": \"en\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "getRelations(sample3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semantic Roles Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here we are going to analyze the following string for relevant semantic roles: \n",
      "IBM is an American multinational technology company headquartered in Armok, New York, United States, with operations in over 170 countries.\n"
     ]
    }
   ],
   "source": [
    "print (\"Here we are going to analyze the following string for relevant semantic roles: \\n{}\".format(sample3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function uses the natural language understanding object to analyze the provided text to find relevant semantic roles in the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getSemanticRoles(text):\n",
    "    response=nlu.analyze(\n",
    "        text=text,\n",
    "        features=Features(\n",
    "            semantic_roles=SemanticRolesOptions(\n",
    "                # Semantic Role Options\n",
    "                entities=True,\n",
    "                keywords=True,\n",
    "                limit=50\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    print ('Raw Results: ')\n",
    "    print(json.dumps(response, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are the raw results. From this it can be seen that the action in the sentence is \"is\", the verb is \"be\", etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Results: \n",
      "{\n",
      "  \"usage\": {\n",
      "    \"text_characters\": 139,\n",
      "    \"features\": 1,\n",
      "    \"text_units\": 1\n",
      "  },\n",
      "  \"semantic_roles\": [\n",
      "    {\n",
      "      \"object\": {\n",
      "        \"entities\": [\n",
      "          {\n",
      "            \"disambiguation\": {\n",
      "              \"subtype\": [\n",
      "                \"City\"\n",
      "              ]\n",
      "            },\n",
      "            \"text\": \"Armok\",\n",
      "            \"type\": \"Location\"\n",
      "          },\n",
      "          {\n",
      "            \"disambiguation\": {\n",
      "              \"name\": \"New York City\",\n",
      "              \"dbpedia_resource\": \"http://dbpedia.org/resource/New_York_City\",\n",
      "              \"subtype\": [\n",
      "                \"PoliticalDistrict\",\n",
      "                \"GovernmentalJurisdiction\",\n",
      "                \"PlaceWithNeighborhoods\",\n",
      "                \"WineRegion\",\n",
      "                \"CityTown\",\n",
      "                \"FilmScreeningVenue\",\n",
      "                \"City\"\n",
      "              ]\n",
      "            },\n",
      "            \"text\": \"New York\",\n",
      "            \"type\": \"Location\"\n",
      "          },\n",
      "          {\n",
      "            \"disambiguation\": {\n",
      "              \"name\": \"United States\",\n",
      "              \"dbpedia_resource\": \"http://dbpedia.org/resource/United_States\",\n",
      "              \"subtype\": [\n",
      "                \"Region\",\n",
      "                \"AdministrativeDivision\",\n",
      "                \"Country\",\n",
      "                \"GovernmentalJurisdiction\",\n",
      "                \"FilmEditor\",\n",
      "                \"Country\"\n",
      "              ]\n",
      "            },\n",
      "            \"text\": \"United States\",\n",
      "            \"type\": \"Location\"\n",
      "          }\n",
      "        ],\n",
      "        \"text\": \"an American multinational technology company headquartered in Armok, New York, United States,\",\n",
      "        \"keywords\": [\n",
      "          {\n",
      "            \"text\": \"American multinational technology\"\n",
      "          },\n",
      "          {\n",
      "            \"text\": \"Armok\"\n",
      "          },\n",
      "          {\n",
      "            \"text\": \"New York\"\n",
      "          },\n",
      "          {\n",
      "            \"text\": \"United States\"\n",
      "          }\n",
      "        ]\n",
      "      },\n",
      "      \"subject\": {\n",
      "        \"entities\": [\n",
      "          {\n",
      "            \"disambiguation\": {\n",
      "              \"name\": \"IBM\",\n",
      "              \"dbpedia_resource\": \"http://dbpedia.org/resource/IBM\",\n",
      "              \"subtype\": [\n",
      "                \"SoftwareLicense\",\n",
      "                \"Organization\",\n",
      "                \"OperatingSystemDeveloper\",\n",
      "                \"ProcessorManufacturer\",\n",
      "                \"SoftwareDeveloper\",\n",
      "                \"CompanyFounder\",\n",
      "                \"ProgrammingLanguageDesigner\",\n",
      "                \"ProgrammingLanguageDeveloper\"\n",
      "              ]\n",
      "            },\n",
      "            \"text\": \"IBM\",\n",
      "            \"type\": \"Company\"\n",
      "          }\n",
      "        ],\n",
      "        \"text\": \"IBM\"\n",
      "      },\n",
      "      \"action\": {\n",
      "        \"normalized\": \"be\",\n",
      "        \"text\": \"is\",\n",
      "        \"verb\": {\n",
      "          \"tense\": \"present\",\n",
      "          \"text\": \"be\"\n",
      "        }\n",
      "      },\n",
      "      \"sentence\": \"IBM is an American multinational technology company headquartered in Armok, New York, United States, with operations in over 170 countries.\"\n",
      "    },\n",
      "    {\n",
      "      \"subject\": {\n",
      "        \"entities\": [],\n",
      "        \"text\": \"an American multinational technology company\",\n",
      "        \"keywords\": [\n",
      "          {\n",
      "            \"text\": \"American multinational technology\"\n",
      "          },\n",
      "          {\n",
      "            \"text\": \"company\"\n",
      "          }\n",
      "        ]\n",
      "      },\n",
      "      \"action\": {\n",
      "        \"normalized\": \"headquarter\",\n",
      "        \"text\": \"headquartered\",\n",
      "        \"verb\": {\n",
      "          \"tense\": \"past\",\n",
      "          \"text\": \"headquarter\"\n",
      "        }\n",
      "      },\n",
      "      \"sentence\": \"IBM is an American multinational technology company headquartered in Armok, New York, United States, with operations in over 170 countries.\"\n",
      "    }\n",
      "  ],\n",
      "  \"language\": \"en\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "getSemanticRoles(sample3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here we are going to analyze the following string for relevant sentiments: \n",
      "IBM is an American multinational technology company headquartered in Armok, New York, United States, with operations in over 170 countries.\n"
     ]
    }
   ],
   "source": [
    "print (\"Here we are going to analyze the following string for relevant sentiments: \\n{}\".format(sample3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function uses the natural language understanding object to analyze the provided text to find the relevant sentiment score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getSentiments(text):\n",
    "    try:\n",
    "        response=nlu.analyze(\n",
    "            text=text,\n",
    "            features=Features(\n",
    "                sentiment=SentimentOptions(\n",
    "                    # Sentiment Options\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    except:\n",
    "        response = []\n",
    "        \n",
    "    print ('Raw Results: ')\n",
    "    print(json.dumps(response, indent=2))\n",
    "        \n",
    "    return response['sentiment']['document']['score']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are the raw results and the relevant sentiment score for the provided text. Both tweets were classified as negative with really negative sentiment scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Results: \n",
      "{\n",
      "  \"usage\": {\n",
      "    \"text_characters\": 133,\n",
      "    \"features\": 1,\n",
      "    \"text_units\": 1\n",
      "  },\n",
      "  \"language\": \"en\",\n",
      "  \"sentiment\": {\n",
      "    \"document\": {\n",
      "      \"score\": -0.939078,\n",
      "      \"label\": \"negative\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "The following text has a sentiment score of -0.939078: can't decide if i should even watch the #democraticdebate or is it not worth the migraine!? #conservative #republican2016 #tcot #ycot \n"
     ]
    }
   ],
   "source": [
    "sentiment = getSentiments(sample1)\n",
    "print (\"\\nThe following text has a sentiment score of {}: {} \".format(sentiment,sample1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Results: \n",
      "{\n",
      "  \"usage\": {\n",
      "    \"text_characters\": 97,\n",
      "    \"features\": 1,\n",
      "    \"text_units\": 1\n",
      "  },\n",
      "  \"language\": \"en\",\n",
      "  \"sentiment\": {\n",
      "    \"document\": {\n",
      "      \"score\": -0.924145,\n",
      "      \"label\": \"negative\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "The following text has a sentiment score of -0.924145: i would be afraid of taking questions too, if i were up to the crap harper's been up to. #cdnpoli \n"
     ]
    }
   ],
   "source": [
    "sentiment = getSentiments(sample2)\n",
    "print (\"\\nThe following text has a sentiment score of {}: {} \".format(sentiment,sample2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
